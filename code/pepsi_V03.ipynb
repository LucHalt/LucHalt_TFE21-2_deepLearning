{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pprint\n",
        "\n",
        "# Log in to your W&B account\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()\n",
        "# API: 18fe909a998e642a33986bd03c61ee2c6922f72d\n",
        "\n",
        "\n",
        "# Loading the MNIST dataset in one line\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train_normalized = x_train/255\n",
        "x_test_normalized = x_test/255\n",
        "x_train= x_train_normalized.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test_normalized.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Printing the shape\n",
        "print('x_train:', x_train.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('x_test:', x_test.shape)\n",
        "print('y_test:', y_test.shape)"
      ],
      "metadata": {
        "id": "59e76d83-758d-4236-b2ba-5d79964f0202",
        "execution": {
          "iopub.status.busy": "2023-11-06T11:08:09.606352Z",
          "iopub.execute_input": "2023-11-06T11:08:09.606782Z",
          "iopub.status.idle": "2023-11-06T11:08:21.806883Z",
          "shell.execute_reply.started": "2023-11-06T11:08:09.606747Z",
          "shell.execute_reply": "2023-11-06T11:08:21.805505Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Net(neurons1=26, neurons2=26, neurons3=54, acivation1='relu',activation2='relu',activation3='sigmoid',do1=0.2, do2=0.2, do3=0.2, do3=0.2, gn1=0.1):\n",
        "    return tf.keras.models.Sequential(\n",
        "    [\n",
        "    tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(filters=neurons1, kernel_size=5, padding='same', activation=acivation1),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(do1),\n",
        "    tf.keras.layers.Conv2D(filters=neurons2, kernel_size=5, padding='same', activation=activation2, kernel_initializer=tf.keras.initializers.HeNormal()), #new\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(do2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(do3),\n",
        "    tf.keras.layers.Dense(neurons3, kernel_regularizer = tf.keras.regularizers.l2(0.07), activation = activation3),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(do4),\n",
        "    tf.keras.layers.GaussianNoise(gn1),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = Net()\n",
        "model.summary()\n",
        "\n",
        "def get_optimizer(lr=1e-3, optimizer=\"adam\"):\n",
        "    \"Select optmizer between adam and sgd with momentum\"\n",
        "    if optimizer.lower() == \"adam\":\n",
        "        return tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    if optimizer.lower() == \"sgd\":\n",
        "        return tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.1)\n",
        "\n",
        "def train(model, batch_size=64, epochs=10, lr=1e-3, optimizer='adam', log_freq='epoch'):\n",
        "\n",
        "    # Compile model like you usually do.\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Compile modell\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy() #from_logits=True\n",
        "    sampleID = 100\n",
        "    loss_fn(y_train[:1], model(x_train[sampleID-1:sampleID]).numpy()).numpy()\n",
        "\n",
        "    model.compile(loss=loss_fn,\n",
        "                  optimizer=get_optimizer(lr, optimizer),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # callback setup\n",
        "    wandb_callbacks = [wandb.keras.WandbCallback(log_freq=log_freq,save_model=(False),) ]\n",
        "\n",
        "    # Train your model\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data = (x_test, y_test),\n",
        "        callbacks = [wandb_callbacks]\n",
        "        )\n",
        "\n",
        "# Configure Sweep\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'val_accuracy'\n",
        "    }\n",
        "    'early_terminate': {\n",
        "        \"type\": \"hyperband\",\n",
        "        \"eta\": 2,\n",
        "        \"min_iter\":3\n",
        "     }\n",
        "}\n",
        "parameters_dict = {\n",
        "    'optimizer': {\n",
        "        'value': 'adam'\n",
        "        },\n",
        "    'epochs': {\n",
        "        'value': 20\n",
        "        },\n",
        "    'batch_size' : {\n",
        "        'value': 32\n",
        "        },\n",
        "    'learning_rate': {\n",
        "        'value': 1e-4\n",
        "    },\n",
        "     'neurons1': {\n",
        "        'value': 26\n",
        "    },\n",
        "    'neurons2': {\n",
        "        'value': 26\n",
        "    },\n",
        "    'neurons3': {\n",
        "        'value': 54\n",
        "    },\n",
        "\n",
        "    'activation1' : {\n",
        "        'value' :  ['relu']\n",
        "    },\n",
        "    'activation2' : {\n",
        "        'value' : ['relu']\n",
        "    },\n",
        "    'activation3' : {\n",
        "        'value' : ['sigmoid']\n",
        "    },\n",
        "    'do1' : {\n",
        "        'values' : list(range(0.01,0.8,0.05))\n",
        "    },\n",
        "    'do2' : {\n",
        "        'values' : list(range(0.01,0.8,0.05))\n",
        "    },\n",
        "    'do3' : {\n",
        "        'values' : list(range(0.01,0.8,0.05))\n",
        "    },\n",
        "    'do4' : {\n",
        "        'values' : list(range(0.01,0.8,0.05))\n",
        "    },\n",
        "    'gn1' : {\n",
        "        'values' : list(range(0.01,0.8,0.05))\n",
        "    }\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "pprint.pprint(sweep_config)\n",
        "\n",
        "def sweep_train(config_defaults=None):\n",
        "    # Initialize wandb with a sample project name\n",
        "    with wandb.init(config=config_defaults):  # this gets over-written in the Sweep\n",
        "\n",
        "        # Specify the other hyperparameters to the configuration, if any\n",
        "        wandb.config.architecture_name = \"V03\"\n",
        "        wandb.config.dataset_name = \"MNIST\"\n",
        "\n",
        "        # initialize model\n",
        "        model = Net(wandb.config.neurons1, wandb.config.neurons2, wandb.config.neurons3)\n",
        "\n",
        "        train(model,\n",
        "              wandb.config.batch_size,\n",
        "              wandb.config.epochs,\n",
        "              wandb.config.learning_rate,\n",
        "              wandb.config.optimizer)\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"V03_Dropout\")\n",
        "wandb.agent(sweep_id, function=sweep_train, count=30)"
      ],
      "metadata": {
        "id": "1b2e1c5b-39af-4a87-86dc-4af94b309aa7",
        "outputId": "13a87668-a333-469e-bb7a-24c19d8be12b",
        "execution": {
          "iopub.status.busy": "2023-11-06T11:10:07.023695Z",
          "iopub.execute_input": "2023-11-06T11:10:07.024067Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_4 (Conv2D)           (None, 28, 28, 28)        728       \n                                                                 \n batch_normalization_4 (Batc  (None, 28, 28, 28)       112       \n hNormalization)                                                 \n                                                                 \n max_pooling2d_4 (MaxPooling  (None, 14, 14, 28)       0         \n 2D)                                                             \n                                                                 \n conv2d_5 (Conv2D)           (None, 14, 14, 16)        11216     \n                                                                 \n max_pooling2d_5 (MaxPooling  (None, 7, 7, 16)         0         \n 2D)                                                             \n                                                                 \n dropout_4 (Dropout)         (None, 7, 7, 16)          0         \n                                                                 \n flatten_2 (Flatten)         (None, 784)               0         \n                                                                 \n dropout_5 (Dropout)         (None, 784)               0         \n                                                                 \n dense_4 (Dense)             (None, 64)                50240     \n                                                                 \n batch_normalization_5 (Batc  (None, 64)               256       \n hNormalization)                                                 \n                                                                 \n gaussian_noise_2 (GaussianN  (None, 64)               0         \n oise)                                                           \n                                                                 \n dense_5 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 63,202\nTrainable params: 63,018\nNon-trainable params: 184\n_________________________________________________________________\n{'method': 'bayes',\n 'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n 'parameters': {'activation1': {'value': ['relu']},\n                'activation2': {'value': ['relu']},\n                'activation3': {'value': ['sigmoid']},\n                'batch_size': {'value': 32},\n                'epochs': {'value': 50},\n                'learning_rate': {'values': [7e-06, 9e-06]},\n                'neurons1': {'values': [18, 20, 22, 24, 26]},\n                'neurons2': {'values': [24, 25, 26, 27]},\n                'neurons3': {'values': [44, 48, 52]},\n                'optimizer': {'value': 'adam'}}}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Create sweep with ID: h37rw6i5\nSweep URL: https://wandb.ai/luchalt/V02d_Langzeit/sweeps/h37rw6i5\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after the training finishes, we will also save Marvin in Keras style (HDF5), so we do not have to\n",
        "# train him again\n",
        "# every time we start our computer. Obviously, by changing the model_name, you can also save different\n",
        "# configurations of Marvin. The name has to be a string, like this: 'name.h5'\n",
        "model_name = 'pepsi_p62k_a9915'\n",
        "model.save(model_name, save_format='h5')\n",
        "\n",
        "# It is best practice to indicate what configuration changes you did within the name, so you know\n",
        "# which model you need to load already from its name\n",
        "# Let's say instead of a learning rate of 0.001 you used 0.1, your naming could then look like:\n",
        "# 'marvin_lr01.h5'\n",
        "\n",
        "print('Success! You saved Marvin as: ', model_name)"
      ],
      "metadata": {
        "id": "f9f8b49b-a5e8-49d6-acf2-7e21b2a3ebbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a saved marvin configuration you want to evaluate\n",
        "model_name = 'pepsi_lr03'\n",
        "pepsi_reloaded = tf.keras.models.load_model(model_name)\n",
        "\n",
        "# Let Marvin predict on the test set, so we have some data to evaluate his performance.\n",
        "predictions = pepsi_reloaded.predict([x_test])\n",
        "# predictions = pepsi.predict([x_test])\n",
        "\n",
        "# Remember that the prediction of Marvin is a probability distribution over all ten-digit classes\n",
        "# We want him to assign the digit class with the highest probability to the sample.\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "#pd.DataFrame(predictions)\n",
        "\n",
        "# Plot for the intuitive approach\n",
        "\n",
        "numbers_to_display = 196\n",
        "num_cells = math.ceil(math.sqrt(numbers_to_display))\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for plot_index in range(numbers_to_display):\n",
        "    predicted_label = predictions[plot_index]\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    color_map = 'Greens' if predicted_label == y_test[plot_index] else 'Reds'\n",
        "    plt.subplot(num_cells, num_cells, plot_index + 1)\n",
        "    plt.imshow(x_test_normalized[plot_index].reshape((28, 28)), cmap=color_map)\n",
        "    plt.xlabel(predicted_label)\n",
        "\n",
        "plt.subplots_adjust(hspace=1, wspace=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a060138f-a493-48c1-ad04-aeabd8b8a2eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = tf.math.confusion_matrix(y_test, predictions)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(9, 7))\n",
        "sn.heatmap(\n",
        "    confusion_matrix,\n",
        "    annot=True,\n",
        "    linewidths=.7,\n",
        "    fmt=\"d\",\n",
        "    square=True,\n",
        "    ax=ax,\n",
        "    cmap=\"viridis\",\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "221c7109-9e25-47f3-8d11-b31043913d42"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}