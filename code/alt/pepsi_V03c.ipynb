{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pprint\nimport numpy as np\n\n# Log in to your W&B account\n!pip install wandb\nimport wandb\nwandb.login()\n# API: 18fe909a998e642a33986bd03c61ee2c6922f72d\n\n\n# Loading the MNIST dataset in one line\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\nx_train_normalized = x_train/255\nx_test_normalized = x_test/255\nx_train= x_train_normalized.reshape(-1, 28, 28, 1)\nx_test = x_test_normalized.reshape(-1, 28, 28, 1)\n\n# Printing the shape\nprint('x_train:', x_train.shape)\nprint('y_train:', y_train.shape)\nprint('x_test:', x_test.shape)\nprint('y_test:', y_test.shape)","metadata":{"id":"59e76d83-758d-4236-b2ba-5d79964f0202","execution":{"iopub.status.busy":"2023-11-06T19:28:10.095447Z","iopub.execute_input":"2023-11-06T19:28:10.096078Z","iopub.status.idle":"2023-11-06T19:28:39.483651Z","shell.execute_reply.started":"2023-11-06T19:28:10.096042Z","shell.execute_reply":"2023-11-06T19:28:39.482583Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.9)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 0s 0us/step\nx_train: (60000, 28, 28, 1)\ny_train: (60000,)\nx_test: (10000, 28, 28, 1)\ny_test: (10000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"def Net(neurons1=26, neurons2=26, neurons3=54, acivation1='relu',activation2='relu',activation3='sigmoid',do1=0.2, do2=0.2, do3=0.2, do4=0.2, gn1=0.1):\n    return tf.keras.models.Sequential(\n    [\n    tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n    tf.keras.layers.Conv2D(filters=neurons1, kernel_size=5, padding='same', activation=acivation1),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(do1),\n    tf.keras.layers.Conv2D(filters=neurons2, kernel_size=5, padding='same', activation=activation2, kernel_initializer=tf.keras.initializers.HeNormal()), #new\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(do2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(do3),\n    tf.keras.layers.Dense(neurons3, kernel_regularizer = tf.keras.regularizers.l2(0.07), activation = activation3),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(do4),\n    tf.keras.layers.GaussianNoise(gn1),\n    tf.keras.layers.Dense(10, activation='softmax')\n    ]\n)\n\nmodel = Net()\nmodel.summary()\n\ndef get_optimizer(lr=1e-3, optimizer=\"adam\"):\n    \"Select optmizer between adam and sgd with momentum\"\n    if optimizer.lower() == \"adam\":\n        return tf.keras.optimizers.Adam(learning_rate=lr)\n    if optimizer.lower() == \"sgd\":\n        return tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.1)\n\ndef train(model, batch_size=64, epochs=10, lr=1e-3, optimizer='adam', log_freq='epoch'):\n\n    # Compile model like you usually do.\n    tf.keras.backend.clear_session()\n\n    # Compile modell\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy() #from_logits=True\n    sampleID = 100\n    loss_fn(y_train[:1], model(x_train[sampleID-1:sampleID]).numpy()).numpy()\n\n    model.compile(loss=loss_fn,\n                  optimizer=get_optimizer(lr, optimizer),\n                  metrics=['accuracy'])\n\n    # callback setup\n    wandb_callbacks = [wandb.keras.WandbCallback(log_freq=log_freq,save_model=(False),) ]\n\n    # Train your model\n    model.fit(\n        x_train,\n        y_train,\n        epochs=epochs,\n        batch_size=batch_size,\n        validation_data = (x_test, y_test),\n        callbacks = [wandb_callbacks]\n        )\n\n# Configure Sweep\nsweep_config = {\n    'method': 'random',\n    'metric': {\n        'goal': 'maximize',\n        'name': 'val_accuracy'\n    }\n}\nparameters_dict = {\n    'optimizer': {\n        'value': 'adam'\n        },\n    'epochs': {\n        'value': 100\n        },\n    'batch_size' : {\n        'value': [16,32,64,128,256,512]\n        },\n    'learning_rate': {\n        'values': [1e-5,1e-4,1e-3,1e-2]\n    },\n     'neurons1': {\n        'value': 26\n    },\n    'neurons2': {\n        'value': 26\n    },\n    'neurons3': {\n        'value': 54\n    },\n\n    'activation1' : {\n        'value' :  ['relu']\n    },\n    'activation2' : {\n        'value' : ['relu']\n    },\n    'activation3' : {\n        'value' : ['sigmoid']\n    },\n    'do1' : {\n        'value' : 0.7\n    },\n    'do2' : {\n        'value' : 0.4\n    },\n    'do3' : {\n        'value' : 0.1\n    },\n    'do4' : {\n        'value' : 0.45\n    },\n    'gn1' : {\n        'value' : 0.7\n    }\n}\nsweep_config['parameters'] = parameters_dict\npprint.pprint(sweep_config)\n\ndef sweep_train(config_defaults=None):\n    # Initialize wandb with a sample project name\n    with wandb.init(config=config_defaults):  # this gets over-written in the Sweep\n\n        # Specify the other hyperparameters to the configuration, if any\n        wandb.config.architecture_name = \"V03c\"\n        wandb.config.dataset_name = \"MNIST\"\n\n        # initialize model\n        model = Net(wandb.config.neurons1, wandb.config.neurons2, wandb.config.neurons3)\n\n        train(model,\n              wandb.config.batch_size,\n              wandb.config.epochs,\n              wandb.config.learning_rate,\n              wandb.config.optimizer)\n\nsweep_id = wandb.sweep(sweep_config, project=\"V03_Dropout\")\nwandb.agent(sweep_id, function=sweep_train, count=30)","metadata":{"id":"1b2e1c5b-39af-4a87-86dc-4af94b309aa7","outputId":"13a87668-a333-469e-bb7a-24c19d8be12b","execution":{"iopub.status.busy":"2023-11-06T19:35:03.248102Z","iopub.execute_input":"2023-11-06T19:35:03.248458Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 28, 28, 26)        676       \n                                                                 \n batch_normalization (BatchN  (None, 28, 28, 26)       104       \n ormalization)                                                   \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 14, 14, 26)       0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 14, 14, 26)        0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 14, 14, 26)        16926     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 7, 7, 26)         0         \n 2D)                                                             \n                                                                 \n dropout_1 (Dropout)         (None, 7, 7, 26)          0         \n                                                                 \n flatten (Flatten)           (None, 1274)              0         \n                                                                 \n dropout_2 (Dropout)         (None, 1274)              0         \n                                                                 \n dense (Dense)               (None, 54)                68850     \n                                                                 \n batch_normalization_1 (Batc  (None, 54)               216       \n hNormalization)                                                 \n                                                                 \n dropout_3 (Dropout)         (None, 54)                0         \n                                                                 \n gaussian_noise (GaussianNoi  (None, 54)               0         \n se)                                                             \n                                                                 \n dense_1 (Dense)             (None, 10)                550       \n                                                                 \n=================================================================\nTotal params: 87,322\nTrainable params: 87,162\nNon-trainable params: 160\n_________________________________________________________________\n{'method': 'random',\n 'metric': {'goal': 'maximize', 'name': 'val_accuracy'},\n 'parameters': {'activation1': {'value': ['relu']},\n                'activation2': {'value': ['relu']},\n                'activation3': {'value': ['sigmoid']},\n                'batch_size': {'value': [16, 32, 64, 128, 256, 512]},\n                'do1': {'value': 0.7},\n                'do2': {'value': 0.4},\n                'do3': {'value': 0.1},\n                'do4': {'value': 0.45},\n                'epochs': {'value': 100},\n                'gn1': {'value': 0.7},\n                'learning_rate': {'values': [1e-05, 0.0001, 0.001, 0.01]},\n                'neurons1': {'value': 26},\n                'neurons2': {'value': 26},\n                'neurons3': {'value': 54},\n                'optimizer': {'value': 'adam'}}}\nCreate sweep with ID: fh5qi0pw\nSweep URL: https://wandb.ai/luchalt/V03_Dropout/sweeps/fh5qi0pw\n","output_type":"stream"}]},{"cell_type":"code","source":"# after the training finishes, we will also save Marvin in Keras style (HDF5), so we do not have to\n# train him again\n# every time we start our computer. Obviously, by changing the model_name, you can also save different\n# configurations of Marvin. The name has to be a string, like this: 'name.h5'\nmodel_name = 'pepsi_p62k_a9915'\nmodel.save(model_name, save_format='h5')\n\n# It is best practice to indicate what configuration changes you did within the name, so you know\n# which model you need to load already from its name\n# Let's say instead of a learning rate of 0.001 you used 0.1, your naming could then look like:\n# 'marvin_lr01.h5'\n\nprint('Success! You saved Marvin as: ', model_name)","metadata":{"id":"f9f8b49b-a5e8-49d6-acf2-7e21b2a3ebbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load a saved marvin configuration you want to evaluate\nmodel_name = 'pepsi_lr03'\npepsi_reloaded = tf.keras.models.load_model(model_name)\n\n# Let Marvin predict on the test set, so we have some data to evaluate his performance.\npredictions = pepsi_reloaded.predict([x_test])\n# predictions = pepsi.predict([x_test])\n\n# Remember that the prediction of Marvin is a probability distribution over all ten-digit classes\n# We want him to assign the digit class with the highest probability to the sample.\npredictions = np.argmax(predictions, axis=1)\n#pd.DataFrame(predictions)\n\n# Plot for the intuitive approach\n\nnumbers_to_display = 196\nnum_cells = math.ceil(math.sqrt(numbers_to_display))\nplt.figure(figsize=(15, 15))\n\nfor plot_index in range(numbers_to_display):\n    predicted_label = predictions[plot_index]\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    color_map = 'Greens' if predicted_label == y_test[plot_index] else 'Reds'\n    plt.subplot(num_cells, num_cells, plot_index + 1)\n    plt.imshow(x_test_normalized[plot_index].reshape((28, 28)), cmap=color_map)\n    plt.xlabel(predicted_label)\n\nplt.subplots_adjust(hspace=1, wspace=0.5)\nplt.show()","metadata":{"id":"a060138f-a493-48c1-ad04-aeabd8b8a2eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix = tf.math.confusion_matrix(y_test, predictions)\n\nf, ax = plt.subplots(figsize=(9, 7))\nsn.heatmap(\n    confusion_matrix,\n    annot=True,\n    linewidths=.7,\n    fmt=\"d\",\n    square=True,\n    ax=ax,\n    cmap=\"viridis\",\n)\nplt.show()","metadata":{"id":"221c7109-9e25-47f3-8d11-b31043913d42"},"execution_count":null,"outputs":[]}]}