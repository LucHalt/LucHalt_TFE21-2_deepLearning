{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version:', tf.__version__, '\\n')\n",
    "\n",
    "# Keras is a model-level library, meaning that it is built upon tensorflow (using it as a backend) - allowing for\n",
    "# high-level building blocks. Making it even easier to design neural networks.\n",
    "# We will access it as tf.keras\n",
    "\n",
    "# The tf and k abbreviations are best practice (same for numpy np and pandas pd),\n",
    "# since you do not want to type T E N S O R F L O W all over your code.\n",
    "# They are prevalent all over the industry and academia in a way that you'll risk a fight if you import them differently.\n",
    "\n",
    "# Loading the MNIST dataset in one line\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train_normalized = x_train/255\n",
    "x_test_normalized = x_test/255\n",
    "\n",
    "# in the next step, we also need to reshape our input to fit our input layer later on.\n",
    "# This is due to keras expecting a definition for how many channels your input sample has, as we\n",
    "# deal with gray scale this is 1.\n",
    "x_train= x_train_normalized.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test_normalized.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_0eMI4k9bCZF",
    "outputId": "dffad165-ad63-48e0-b822-029da63aaf40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.1 \n",
      "\n",
      "Digit: 9\n",
      "Index: 39293\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (60000, 28, 28, 1)\n",
      "y_train: (60000,)\n",
      "x_test: (10000, 28, 28, 1)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version:', tf.__version__, '\\n')\n",
    "\n",
    "# Keras is a model-level library, meaning that it is built upon tensorflow (using it as a backend) - allowing for\n",
    "# high-level building blocks. Making it even easier to design neural networks.\n",
    "# We will access it as tf.keras\n",
    "\n",
    "# The tf and k abbreviations are best practice (same for numpy np and pandas pd),\n",
    "# since you do not want to type T E N S O R F L O W all over your code.\n",
    "# They are prevalent all over the industry and academia in a way that you'll risk a fight if you import them differently.\n",
    "\n",
    "# Loading the MNIST dataset in one line\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train_normalized = x_train/255\n",
    "x_test_normalized = x_test/255\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "x_train_best = []  # Array für die ähnlichsten Bilder\n",
    "y_train_best = []  # Array für die zugehörigen Labels\n",
    "similar_indices = [47647]  # Array für die Indizes der ähnlichsten Bilder\n",
    "\n",
    "# Berechnung der ähnlichsten Ziffern für jede Klasse von 0 bis 9\n",
    "for digit in range(10):\n",
    "    \n",
    "    print('Digit:', digit)\n",
    "    # Filtern der Ziffern nach ihrer Klasse\n",
    "    class_images = x_train[y_train == digit]\n",
    "\n",
    "    # Berechnung der durchschnittlichen Cosinus-Ähnlichkeit für jede Ziffer zu anderen Ziffern derselben Klasse\n",
    "    similarities = []\n",
    "    for i, image in enumerate(class_images):\n",
    "        avg_similarity = 0\n",
    "        for other_image in class_images:\n",
    "            if not np.array_equal(image, other_image):\n",
    "                # Umwandlung von 28x28 Bildern in Vektoren für Cosinus-Ähnlichkeit\n",
    "                image_vector = image.flatten()\n",
    "                other_image_vector = other_image.flatten()\n",
    "                # Berechnung der Cosinus-Ähnlichkeit\n",
    "                cosine_similarity = 1 - distance.cosine(image_vector, other_image_vector)\n",
    "                avg_similarity += cosine_similarity\n",
    "        avg_similarity /= len(class_images) - 1  # Durchschnittliche Ähnlichkeit zu allen anderen Ziffern der Klasse außer sich selbst\n",
    "        similarities.append((i, avg_similarity))\n",
    "\n",
    "    # Sortieren nach der durchschnittlichen Ähnlichkeit und Auswahl der ähnlichsten Ziffer\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    most_similar_index = similarities[0][0]\n",
    "\n",
    "    most_similar_index_train_images = np.where((y_train == digit))[0][most_similar_index]\n",
    "    most_similar_digit = x_train[most_similar_index_train_images]\n",
    "\n",
    "    print('Index:', most_similar_index_train_images)\n",
    "        \n",
    "    # Hinzufügen des ähnlichsten Bildes, seines Labels und seines Index im train_images Array in den Arrays\n",
    "    x_train_best.append(most_similar_digit)\n",
    "    y_train_best.append(digit)\n",
    "    similar_indices.append(most_similar_index_train_images)\n",
    "\n",
    "# Umwandeln der Listen in numpy arrays\n",
    "x_train_best = np.array(x_train_best)\n",
    "y_train_best = np.array(y_train_best)\n",
    "similar_indices = np.array(similar_indices)\n",
    "\n",
    "# in the next step, we also need to reshape our input to fit our input layer later on.\n",
    "# This is due to keras expecting a definition for how many channels your input sample has, as we\n",
    "# deal with gray scale this is 1.\n",
    "x_train= x_train_normalized.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test_normalized.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Printing the shape\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_best_index = [47647, 17775, 42830, 13519, 1273,\n",
    "                    26066,\n",
    "                    21901, 10297, 46338, 39293]\n",
    "\n",
    "x_train_b = []\n",
    "y_train_b = []\n",
    "\n",
    "for i in range(10):\n",
    "                \n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[train_best_index[i]], cmap=plt.cm.binary)\n",
    "    plt.xlabel(y_train[train_best_index[i]])\n",
    "\n",
    "    x_train_b.append(x_train[train_best_index[i]])\n",
    "    y_train_b.append(y_train[train_best_index[i]])\n",
    "    \n",
    "# Umwandeln der Listen in numpy arrays\n",
    "x_train_b = np.array(x_train_b)\n",
    "y_train_b = np.array(y_train_b)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "oUziIXh2bCZK",
    "outputId": "bd3fa80b-f167-4041-ca82-bd843d012576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_60 (Sequential)  (None, 3, 3, 64)          23296     \n",
      "                                                                 \n",
      " sequential_61 (Sequential)  (None, 10)                31083     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54379 (212.42 KB)\n",
      "Trainable params: 54379 (212.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_encoder = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, kernel_size=3, padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2)\n",
    "])\n",
    "conv_decoder = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding='valid', activation=\"relu\", input_shape=[3, 3, 64]),\n",
    "    \n",
    "    tf.keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding='relu', activation=\"relu\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding='relu', activation=\"sigmoid\"),\n",
    "    \n",
    "    tf.keras.layers.Reshape([28, 28]),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),    \n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "pepsi = tf.keras.models.Sequential([conv_encoder, conv_decoder])\n",
    "\n",
    "pepsi.summary()\n",
    "\n",
    "# Define your loss\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# print(-tf.math.log(1/10))\n",
    "\n",
    "sampleID = 1\n",
    "loss_fn(y_train_b[:1], pepsi(x_train_b[sampleID-1:sampleID]).numpy()).numpy()\n",
    "\n",
    "# Compiling basically means to prepare the training routine for your model which consists of the optimizer,\n",
    "# the loss, and the metrics which are to be reported during training\n",
    "\n",
    "pepsi.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.003),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "X8d40pU-bCZL",
    "outputId": "f164028f-9ff1-4b5a-c748-e2750b5cba3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.3056 - accuracy: 0.1000 - val_loss: 2.3177 - val_accuracy: 0.1033 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.2920 - accuracy: 0.2000 - val_loss: 2.3035 - val_accuracy: 0.1050 - lr: 9.9500e-04\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.2717 - accuracy: 0.1000 - val_loss: 2.2887 - val_accuracy: 0.0974 - lr: 9.9003e-04\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.2685 - accuracy: 0.1000 - val_loss: 2.2778 - val_accuracy: 0.0974 - lr: 9.8507e-04\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.2532 - accuracy: 0.1000 - val_loss: 2.2712 - val_accuracy: 0.1107 - lr: 9.8015e-04\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.2629 - accuracy: 0.1000 - val_loss: 2.2670 - val_accuracy: 0.1050 - lr: 9.7525e-04\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.2375 - accuracy: 0.1000 - val_loss: 2.2623 - val_accuracy: 0.1112 - lr: 9.7037e-04\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.2327 - accuracy: 0.1000 - val_loss: 2.2559 - val_accuracy: 0.1247 - lr: 9.6552e-04\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.2266 - accuracy: 0.2000 - val_loss: 2.2475 - val_accuracy: 0.1514 - lr: 9.6069e-04\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.1787 - accuracy: 0.2000 - val_loss: 2.2380 - val_accuracy: 0.2858 - lr: 9.5589e-04\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.1730 - accuracy: 0.4000 - val_loss: 2.2286 - val_accuracy: 0.3669 - lr: 9.5111e-04\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 14s 14s/step - loss: 2.1816 - accuracy: 0.6000 - val_loss: 2.2201 - val_accuracy: 0.3462 - lr: 9.4635e-04\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.1639 - accuracy: 0.5000 - val_loss: 2.2122 - val_accuracy: 0.2745 - lr: 9.4162e-04\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.1666 - accuracy: 0.4000 - val_loss: 2.2036 - val_accuracy: 0.2314 - lr: 9.3691e-04\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.1263 - accuracy: 0.5000 - val_loss: 2.1932 - val_accuracy: 0.2239 - lr: 9.3223e-04\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.1392 - accuracy: 0.3000 - val_loss: 2.1806 - val_accuracy: 0.2295 - lr: 9.2757e-04\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.1124 - accuracy: 0.3000 - val_loss: 2.1652 - val_accuracy: 0.2506 - lr: 9.2293e-04\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.1020 - accuracy: 0.6000 - val_loss: 2.1486 - val_accuracy: 0.2769 - lr: 9.1832e-04\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 17s 17s/step - loss: 2.0521 - accuracy: 0.5000 - val_loss: 2.1311 - val_accuracy: 0.3114 - lr: 9.1372e-04\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.0524 - accuracy: 0.3000 - val_loss: 2.1136 - val_accuracy: 0.3397 - lr: 9.0916e-04\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1.9522 - accuracy: 0.4000 - val_loss: 2.0956 - val_accuracy: 0.3507 - lr: 9.0461e-04\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 11s 11s/step - loss: 1.9908 - accuracy: 0.6000 - val_loss: 2.0770 - val_accuracy: 0.3594 - lr: 9.0009e-04\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 13s 13s/step - loss: 1.9600 - accuracy: 0.4000 - val_loss: 2.0585 - val_accuracy: 0.3621 - lr: 8.9559e-04\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.9127 - accuracy: 0.7000 - val_loss: 2.0398 - val_accuracy: 0.3617 - lr: 8.9111e-04\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 10s 10s/step - loss: 1.8755 - accuracy: 0.9000 - val_loss: 2.0203 - val_accuracy: 0.3701 - lr: 8.8665e-04\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 12s 12s/step - loss: 1.9105 - accuracy: 0.6000 - val_loss: 1.9999 - val_accuracy: 0.3902 - lr: 8.8222e-04\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8042 - accuracy: 0.8000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 30\u001b[0m\n\u001b[0;32m     18\u001b[0m datagen \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mImageDataGenerator(\n\u001b[0;32m     19\u001b[0m             rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,  \n\u001b[0;32m     20\u001b[0m             zoom_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m             horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     27\u001b[0m             vertical_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m datagen\u001b[38;5;241m.\u001b[39mfit(x_train)\n\u001b[1;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mpepsi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mvlr2\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;66;43;03m#]#model_checkpoint]\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m (test_loss, test_acc) \u001b[38;5;241m=\u001b[39m pepsi\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, test_loss)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1777\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1778\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1789\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1790\u001b[0m     )\n\u001b[1;32m-> 1791\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1804\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1806\u001b[0m }\n\u001b[0;32m   1807\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2200\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2196\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2197\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2198\u001b[0m             ):\n\u001b[0;32m   2199\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2200\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2201\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2202\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2203\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2204\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2207\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2208\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:4000\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[0;32m   3999\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[1;32m-> 4000\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4001\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   4002\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor = 0.95, patience=10, min_lr=0.0001)\n",
    "vlr2 = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.995 ** x)\n",
    "\n",
    "er = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=1,\n",
    "        restore_best_weights=True\n",
    ")\n",
    "checkpoint_filepath = 'tmp/model.{val_accuracy:.4f}.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_freq= 'epoch'\n",
    ")\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  \n",
    "            zoom_range = 0.2,\n",
    "            shear_range=0.1,\n",
    "            width_shift_range=0.1, \n",
    "            height_shift_range=0.1,\n",
    "            rescale=0,\n",
    "            fill_mode = 'nearest',\n",
    "            horizontal_flip=False,\n",
    "            vertical_flip=False)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "history = pepsi.fit(\n",
    "    datagen.flow(x_train_b, y_train_b, batch_size = 10),\n",
    "    epochs=200,\n",
    "    verbose =1,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[vlr2]#]#model_checkpoint]\n",
    ")\n",
    "(test_loss, test_acc) = pepsi.evaluate(x_test, y_test)\n",
    "print(\"Loss: \", test_loss)\n",
    "print(\"Accuracy: \", test_acc)\n",
    "\n",
    "model_name = 'tmpt/model.{test_acc:.4f}.h5'\n",
    "pepsi.save(model_name, save_format='h5')\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-07T13:55:45.923470Z",
     "iopub.status.idle": "2023-11-07T13:55:45.923825Z",
     "shell.execute_reply": "2023-11-07T13:55:45.923659Z",
     "shell.execute_reply.started": "2023-11-07T13:55:45.923643Z"
    },
    "id": "_IuffAeTbCZL"
   },
   "outputs": [],
   "source": [
    "# This line would start up tensorboard for you\n",
    "%tensorboard --logdir logs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-07T13:55:45.924892Z",
     "iopub.status.idle": "2023-11-07T13:55:45.925202Z",
     "shell.execute_reply": "2023-11-07T13:55:45.925061Z",
     "shell.execute_reply.started": "2023-11-07T13:55:45.925047Z"
    },
    "id": "8xB2FVb5bCZM"
   },
   "outputs": [],
   "source": [
    "# after the training finishes, we will also save Marvin in Keras style (HDF5), so we do not have to\n",
    "# train him again\n",
    "# every time we start our computer. Obviously, by changing the model_name, you can also save different\n",
    "# configurations of Marvin. The name has to be a string, like this: 'name.h5'\n",
    "model_name = 'pepsi_V03e_99.6'\n",
    "pepsi.save(model_name, save_format='h5')\n",
    "\n",
    "# It is best practice to indicate what configuration changes you did within the name, so you know\n",
    "# which model you need to load already from its name\n",
    "# Let's say instead of a learning rate of 0.001 you used 0.1, your naming could then look like:\n",
    "# 'marvin_lr01.h5'\n",
    "\n",
    "print('Success! You saved Marvin as: ', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-07T13:55:45.926253Z",
     "iopub.status.idle": "2023-11-07T13:55:45.926586Z",
     "shell.execute_reply": "2023-11-07T13:55:45.926431Z",
     "shell.execute_reply.started": "2023-11-07T13:55:45.926416Z"
    },
    "id": "lcYtZp34bCZM"
   },
   "outputs": [],
   "source": [
    "# Plot for the intuitive approach\n",
    "\n",
    "numbers_to_display = 196\n",
    "num_cells = math.ceil(math.sqrt(numbers_to_display))\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for plot_index in range(numbers_to_display):\n",
    "    predicted_label = predictions[plot_index]\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    color_map = 'Greens' if predicted_label == y_test[plot_index] else 'Reds'\n",
    "    plt.subplot(num_cells, num_cells, plot_index + 1)\n",
    "    plt.imshow(x_test_normalized[plot_index].reshape((28, 28)), cmap=color_map)\n",
    "    plt.xlabel(predicted_label)\n",
    "\n",
    "plt.subplots_adjust(hspace=1, wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCKhienmbCZM",
    "outputId": "ab1c8851-b794-4f29-e1cc-d645120419b2"
   },
   "outputs": [],
   "source": [
    "# load a saved marvin configuration you want to evaluate\n",
    "model_name = 'model.77-0.9975.h5'\n",
    "pepsi_reloaded = tf.keras.models.load_model(model_name)\n",
    "\n",
    "# Let Marvin predict on the test set, so we have some data to evaluate his performance.\n",
    "predictions = pepsi_reloaded.predict([x_test])\n",
    "# predictions = pepsi.predict([x_test])\n",
    "\n",
    "# Remember that the prediction of Marvin is a probability distribution over all ten-digit classes\n",
    "# We want him to assign the digit class with the highest probability to the sample.\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "#pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQPYK-B0bCZM",
    "outputId": "657ce5a1-82e4-4a12-83d2-bae2716ac39c"
   },
   "outputs": [],
   "source": [
    "\n",
    "(test_loss, test_acc) = pepsi_reloaded.evaluate(x_test, y_test)\n",
    "print(\"Loss: \", test_loss)\n",
    "print(\"Accuracy: \", test_acc)\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(y_test, predictions)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 7))\n",
    "sn.heatmap(\n",
    "    confusion_matrix,\n",
    "    annot=True,\n",
    "    linewidths=.7,\n",
    "    fmt=\"d\",\n",
    "    square=True,\n",
    "    ax=ax,\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
