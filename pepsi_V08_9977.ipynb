{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# We will use this cell to import all the packages you will need in the following - think of it as turning on all your systems\n# in your cockpit\n\n# This makes sure that if you change code in your external scripts, they will be updated\n\n\n#import checker\n#import generator\n\nfrom IPython.display import display, clear_output\nimport numpy as np\nimport time\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pandas as pd\n\n#import importlib\n#importlib.reload(checker)\n#importlib.reload(generator)\n\n# now go ahead and Run the cell. This might take a while...\n# while the cell is running, you will see ln[*] next to it. Once it finished, you will see the number of execution\n# In case you want to interrupt the run of a cell, press Ctrl + C (on your german keyboard, this is Strg + C)\n\n# pip install tensorflow\n\n# There is this joke that once you have added this import line to your code,\n# you are allowed to sell your product telling everyone that you are using AI. Life is easy, sometimes.\n\nimport tensorflow as tf\nprint('Tensorflow version:', tf.__version__, '\\n')\n\n# Keras is a model-level library, meaning that it is built upon tensorflow (using it as a backend) - allowing for\n# high-level building blocks. Making it even easier to design neural networks.\n# We will access it as tf.keras\n\n# The tf and k abbreviations are best practice (same for numpy np and pandas pd),\n# since you do not want to type T E N S O R F L O W all over your code.\n# They are prevalent all over the industry and academia in a way that you'll risk a fight if you import them differently.\n\n# Loading the MNIST dataset in one line\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\nx_train_normalized = x_train/255\nx_test_normalized = x_test/255\n\n# in the next step, we also need to reshape our input to fit our input layer later on.\n# This is due to keras expecting a definition for how many channels your input sample has, as we\n# deal with gray scale this is 1.\nx_train= x_train_normalized.reshape(-1, 28, 28, 1)\nx_test = x_test_normalized.reshape(-1, 28, 28, 1)\n\n# Printing the shape\nprint('x_train:', x_train.shape)\nprint('y_train:', y_train.shape)\nprint('x_test:', x_test.shape)\nprint('y_test:', y_test.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0eMI4k9bCZF","outputId":"0640a3ac-dbe0-4e8c-873e-aa02ba88c654","execution":{"iopub.status.busy":"2023-11-27T05:36:20.325499Z","iopub.execute_input":"2023-11-27T05:36:20.326129Z","iopub.status.idle":"2023-11-27T05:36:33.974472Z","shell.execute_reply.started":"2023-11-27T05:36:20.326096Z","shell.execute_reply":"2023-11-27T05:36:33.973489Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow version: 2.13.0 \n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 0s 0us/step\nx_train: (60000, 28, 28, 1)\ny_train: (60000,)\nx_test: (10000, 28, 28, 1)\ny_test: (10000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# This is the moment where you define your model's architecture\n\npepsi = tf.keras.models.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n    \n    tf.keras.layers.Conv2D(filters=28, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=28, kernel_size=3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=28, kernel_size=5, strides=2, padding='same', activation='relu', use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Conv2D(filters=56, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=56, kernel_size=3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=56, kernel_size=5, strides=2, padding='same', activation='relu', use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Conv2D(filters=112, kernel_size=4, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Flatten(),\n\n    tf.keras.layers.Dense(82, kernel_regularizer = tf.keras.regularizers.l2(0.005), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Dense(54, kernel_regularizer = tf.keras.regularizers.l2(0.005), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GaussianNoise(0.75),\n    tf.keras.layers.Dense(10, activation='softmax', use_bias=False)\n    ])\n\npepsi.summary()\n\n# Define your loss\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n# print(-tf.math.log(1/10))\n\nsampleID = 100\nloss_fn(y_train[:1], pepsi(x_train[sampleID-1:sampleID]).numpy()).numpy()\n\n# Compiling basically means to prepare the training routine for your model which consists of the optimizer,\n# the loss, and the metrics which are to be reported during training\n\npepsi.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n              loss= loss_fn,\n              metrics=['accuracy'])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUziIXh2bCZK","outputId":"89a065f8-a611-4d4b-d682-0385d1614376","execution":{"iopub.status.busy":"2023-11-26T18:40:47.770870Z","iopub.execute_input":"2023-11-26T18:40:47.771238Z","iopub.status.idle":"2023-11-26T18:40:55.110362Z","shell.execute_reply.started":"2023-11-26T18:40:47.771210Z","shell.execute_reply":"2023-11-26T18:40:55.109381Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 28, 28, 28)        280       \n                                                                 \n batch_normalization (Batch  (None, 28, 28, 28)        112       \n Normalization)                                                  \n                                                                 \n conv2d_1 (Conv2D)           (None, 28, 28, 28)        7084      \n                                                                 \n batch_normalization_1 (Bat  (None, 28, 28, 28)        112       \n chNormalization)                                                \n                                                                 \n conv2d_2 (Conv2D)           (None, 14, 14, 28)        19600     \n                                                                 \n batch_normalization_2 (Bat  (None, 14, 14, 28)        112       \n chNormalization)                                                \n                                                                 \n dropout (Dropout)           (None, 14, 14, 28)        0         \n                                                                 \n gaussian_noise (GaussianNo  (None, 14, 14, 28)        0         \n ise)                                                            \n                                                                 \n conv2d_3 (Conv2D)           (None, 14, 14, 56)        14168     \n                                                                 \n batch_normalization_3 (Bat  (None, 14, 14, 56)        224       \n chNormalization)                                                \n                                                                 \n conv2d_4 (Conv2D)           (None, 14, 14, 56)        28280     \n                                                                 \n batch_normalization_4 (Bat  (None, 14, 14, 56)        224       \n chNormalization)                                                \n                                                                 \n conv2d_5 (Conv2D)           (None, 7, 7, 56)          78400     \n                                                                 \n batch_normalization_5 (Bat  (None, 7, 7, 56)          224       \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 7, 7, 56)          0         \n                                                                 \n gaussian_noise_1 (Gaussian  (None, 7, 7, 56)          0         \n Noise)                                                          \n                                                                 \n conv2d_6 (Conv2D)           (None, 4, 4, 112)         100464    \n                                                                 \n batch_normalization_6 (Bat  (None, 4, 4, 112)         448       \n chNormalization)                                                \n                                                                 \n flatten (Flatten)           (None, 1792)              0         \n                                                                 \n dense (Dense)               (None, 82)                147026    \n                                                                 \n batch_normalization_7 (Bat  (None, 82)                328       \n chNormalization)                                                \n                                                                 \n dropout_2 (Dropout)         (None, 82)                0         \n                                                                 \n gaussian_noise_2 (Gaussian  (None, 82)                0         \n Noise)                                                          \n                                                                 \n dense_1 (Dense)             (None, 54)                4482      \n                                                                 \n batch_normalization_8 (Bat  (None, 54)                216       \n chNormalization)                                                \n                                                                 \n dropout_3 (Dropout)         (None, 54)                0         \n                                                                 \n gaussian_noise_3 (Gaussian  (None, 54)                0         \n Noise)                                                          \n                                                                 \n dense_2 (Dense)             (None, 10)                540       \n                                                                 \n=================================================================\nTotal params: 402324 (1.53 MB)\nTrainable params: 401324 (1.53 MB)\nNon-trainable params: 1000 (3.91 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import datetime\nimport os\n\n%load_ext tensorboard\nlogdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","metadata":{"id":"uYSG27OSbCZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" tf.keras.layers.Conv2D(filters=28, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=28, kernel_size=3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=28, kernel_size=5, strides=2, padding='same', activation='relu', use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Conv2D(filters=56, kernel_size=3, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=56, kernel_size=3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=56, kernel_size=5, strides=2, padding='same', activation='relu', use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Conv2D(filters=112, kernel_size=4, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Flatten(),\n\n    tf.keras.layers.Dense(82, kernel_regularizer = tf.keras.regularizers.l2(0.005), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Dense(54, kernel_regularizer = tf.keras.regularizers.l2(0.005), activation = 'sigmoid'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GaussianNoise(0.75),","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:40:39.045032Z","iopub.execute_input":"2023-11-26T18:40:39.045599Z","iopub.status.idle":"2023-11-26T18:40:39.058563Z","shell.execute_reply.started":"2023-11-26T18:40:39.045571Z","shell.execute_reply":"2023-11-26T18:40:39.057372Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    tf.keras.layers.BatchNormalization(),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"],"ename":"IndentationError","evalue":"unexpected indent (3052013043.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nets = 50\nmodel = [0] * nets\nfor j in range(nets):\n    \n    model[j] = tf.keras.models.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n    \n    tf.keras.layers.Conv2D(filters=28, kernel_size=3, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=28, kernel_size=3, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=28, kernel_size=5, strides=2, padding='same', activation='relu', use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.GaussianNoise(0.75),\n        \n    tf.keras.layers.Conv2D(filters=56, kernel_size=3, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=56, kernel_size=3, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=56, kernel_size=5, strides=2, padding='same', activation='relu', use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Conv2D(filters=112, kernel_size=4, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Flatten(),\n        \n    tf.keras.layers.Dense(82, kernel_regularizer = tf.keras.regularizers.l2(0.005), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GaussianNoise(0.75),\n\n    tf.keras.layers.Dense(54, kernel_regularizer = tf.keras.regularizers.l2(0.005), activation = 'sigmoid'),\n    tf.keras.layers.BatchNormalization(),\n\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.GaussianNoise(0.75),\n        \n    tf.keras.layers.Dense(10, activation='softmax', use_bias=False)\n    ])\n    \n    # Define your loss\n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    # print(-tf.math.log(1/10))\n    sampleID = 100\n    loss_fn(y_train[:1], model[j](x_train[sampleID-1:sampleID]).numpy()).numpy()\n    \n    model[j].compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n                    loss= loss_fn,\n                    metrics=['accuracy'])\n    \n#vlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor = 0.8, patience =10, min_lr=0.000001)\nvlr2 = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.975 ** x)\n\ner = tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_accuracy\",\n        patience=15,\n        restore_best_weights=True\n)\n\ncheckpoint_filepath = 'tmp1/model.{val_accuracy:.4f}.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True,\n    save_freq= 'epoch'\n)\n    \nfor j in range(nets):\n\n    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n                rotation_range=15,\n                zoom_range = 0.15,\n                shear_range=0.1,\n                width_shift_range=0.1,\n                height_shift_range=0.1,\n                rescale=0,\n                fill_mode = 'nearest',\n                horizontal_flip=False,\n                vertical_flip=False)\n    datagen.fit(x_train)\n\n    history = model[j].fit(\n        datagen.flow(x_train, y_train, batch_size = 32),\n        epochs=500,\n        shuffle = True,\n        validation_data=(x_test, y_test),\n        callbacks=[vlr2, er],# model_checkpoint, ],\n        verbose=1\n    )\n    \n    (test_loss, test_acc) = model[j].evaluate(x_test, y_test)\n    print(\"Loss: \", test_loss)\n    print(\"Accuracy: \", test_acc)\n    model_name = f'tmp/model.{test_acc:.4f}.h5'\n    model[j].save(model_name, save_format='h5')\n  \nplt.figure(figsize=(13, 5))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Test'])\nplt.grid()\nplt.show()","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"X8d40pU-bCZL","outputId":"daa45595-5e7d-4f3a-b057-3ee4b9d9c1fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This line would start up tensorboard for you\n%tensorboard --logdir logs --host localhost","metadata":{"id":"_IuffAeTbCZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# after the training finishes, we will also save Marvin in Keras style (HDF5), so we do not have to\n# train him again\n# every time we start our computer. Obviously, by changing the model_name, you can also save different\n# configurations of Marvin. The name has to be a string, like this: 'name.h5'\nmodel_name = 'tmp/model_99.74'\npepsi.save(model_name, save_format='h5')\n\n# It is best practice to indicate what configuration changes you did within the name, so you know\n# which model you need to load already from its name\n# Let's say instead of a learning rate of 0.001 you used 0.1, your naming could then look like:\n# 'marvin_lr01.h5'\n\nprint('Success! You saved Marvin as: ', model_name)","metadata":{"id":"8xB2FVb5bCZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'tmp/model.0.9974.h5'\npepsi = tf.keras.models.load_model(model_name)\n\ncheckpoint_filepath = 'tmp_re/model.{val_accuracy:.4f}.h5'\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True,\n    save_freq= 'epoch'\n)\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n            rotation_range=15,\n            zoom_range = 0.15,\n            #shear_range=0.20,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rescale=0,\n            fill_mode = 'nearest',\n            horizontal_flip=False,\n            vertical_flip=False)\ndatagen.fit(x_train)\n\nhistory = pepsi.fit(\n    datagen.flow(x_train, y_train, batch_size = 64),\n    epochs=50,\n    shuffle = True,\n    validation_data=(x_test, y_test),\n    callbacks=[model_checkpoint, vlr2],\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T15:27:51.114768Z","iopub.execute_input":"2023-11-26T15:27:51.115149Z","iopub.status.idle":"2023-11-26T15:29:54.720698Z","shell.execute_reply.started":"2023-11-26T15:27:51.115120Z","shell.execute_reply":"2023-11-26T15:29:54.718323Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/50\n  1/938 [..............................] - ETA: 14:27 - loss: 0.0400 - accuracy: 0.9844","output_type":"stream"},{"name":"stderr","text":"2023-11-26 15:27:52.621111: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_47/dropout_188/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"938/938 [==============================] - 23s 23ms/step - loss: 0.1550 - accuracy: 0.9814 - val_loss: 0.1050 - val_accuracy: 0.9933 - lr: 0.0010\nEpoch 2/50\n938/938 [==============================] - 21s 22ms/step - loss: 0.1361 - accuracy: 0.9845 - val_loss: 0.1089 - val_accuracy: 0.9907 - lr: 9.5000e-04\nEpoch 3/50\n938/938 [==============================] - 21s 22ms/step - loss: 0.1369 - accuracy: 0.9844 - val_loss: 0.0995 - val_accuracy: 0.9946 - lr: 9.0250e-04\nEpoch 4/50\n938/938 [==============================] - 21s 23ms/step - loss: 0.1335 - accuracy: 0.9848 - val_loss: 0.1034 - val_accuracy: 0.9937 - lr: 8.5737e-04\nEpoch 5/50\n938/938 [==============================] - 21s 23ms/step - loss: 0.1276 - accuracy: 0.9858 - val_loss: 0.0903 - val_accuracy: 0.9947 - lr: 8.1451e-04\nEpoch 6/50\n707/938 [=====================>........] - ETA: 5s - loss: 0.1234 - accuracy: 0.9857","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m datagen \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mImageDataGenerator(\n\u001b[1;32m     14\u001b[0m             rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m     15\u001b[0m             zoom_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m             horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m             vertical_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m datagen\u001b[38;5;241m.\u001b[39mfit(x_train)\n\u001b[0;32m---> 25\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mpepsi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvlr2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Plot for the intuitive approach\n\nnumbers_to_display = 196\nnum_cells = math.ceil(math.sqrt(numbers_to_display))\nplt.figure(figsize=(15, 15))\n\nfor plot_index in range(numbers_to_display):\n    predicted_label = predictions[plot_index]\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    color_map = 'Greens' if predicted_label == y_test[plot_index] else 'Reds'\n    plt.subplot(num_cells, num_cells, plot_index + 1)\n    plt.imshow(x_test_normalized[plot_index].reshape((28, 28)), cmap=color_map)\n    plt.xlabel(predicted_label)\n\nplt.subplots_adjust(hspace=1, wspace=0.5)\nplt.show()","metadata":{"id":"lcYtZp34bCZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load a saved marvin configuration you want to evaluate\nmodel_name = 'mtmp/model_99.74.h5'\npepsi_reloaded = tf.keras.models.load_model(model_name)\n\n# Let Marvin predict on the test set, so we have some data to evaluate his performance.\npredictions = pepsi_reloaded.predict([x_test])\n# predictions = pepsi.predict([x_test])\n\n# Remember that the prediction of Marvin is a probability distribution over all ten-digit classes\n# We want him to assign the digit class with the highest probability to the sample.\npredictions = np.argmax(predictions, axis=1)\n#pd.DataFrame(predictions)","metadata":{"id":"UCKhienmbCZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n(test_loss, test_acc) = pepsi_reloaded.evaluate(x_test, y_test)\nprint(\"Loss: \", test_loss)\nprint(\"Accuracy: \", test_acc)\n\nconfusion_matrix = tf.math.confusion_matrix(y_test, predictions)\n\nf, ax = plt.subplots(figsize=(9, 7))\nsn.heatmap(\n    confusion_matrix,\n    annot=True,\n    linewidths=.7,\n    fmt=\"d\",\n    square=True,\n    ax=ax,\n    cmap=\"viridis\",\n)\nplt.show()","metadata":{"id":"NQPYK-B0bCZM"},"execution_count":null,"outputs":[]}]}