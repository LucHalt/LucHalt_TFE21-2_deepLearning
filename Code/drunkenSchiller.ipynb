{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pepsi.evaluation.ipynb\n",
        "# by: Tim Lucas Halt (MatrNr. 6682645)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vorbereitung\n",
        "Zunächst werden die notwendigen Bibliotheken installiert und importiert. Möglicherweise ist ein Neustart des Kernels erforderlich."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItsUcrMYYmoP",
        "outputId": "f35e9346-1b2a-46d9-ad5e-de444dca58f5"
      },
      "outputs": [],
      "source": [
        "%pip install scipy\n",
        "%pip install numpy\n",
        "%pip install matplotlib\n",
        "%pip install seaborn\n",
        "%pip install tensorflow\n",
        "%pip install sweetviz\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sweetviz as sw\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8vkgQlrHCS8",
        "outputId": "bb0ccb21-1b82-41bf-f325-14a50dbefda0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Friedrich Schiller\n",
            "Briefe über Don Carlos.\n",
            "Erster Brief.\n",
            "Sie sagen mir, lieber Freund, daß Ihnen die\n"
          ]
        }
      ],
      "source": [
        "# Let's define the URL for the schiller dataset:\n",
        "path = \"https://raw.githubusercontent.com/schutera/tiny_schiller/main/tiny_schiller.txt\"\n",
        "\n",
        "# Let's download the dataset and save it as 'shakespeare.txt':\n",
        "filepath = tf.keras.utils.get_file(\"schiller.txt\", path)\n",
        "\n",
        "# open and read the downloaded text file\n",
        "with open(filepath) as f:\n",
        "    schiller_text = f.read()\n",
        "\n",
        "print(schiller_text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_9xc4evoZAes"
      },
      "outputs": [],
      "source": [
        "tokenizer=keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(schiller_text)\n",
        "\n",
        "max_id=len(tokenizer.word_index)\n",
        "dataset_size=tokenizer.document_count\n",
        "[encoded]=np.array(tokenizer.texts_to_sequences([schiller_text]))-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "DCjhqyeQZH8q"
      },
      "outputs": [],
      "source": [
        "train_size=dataset_size*80//100\n",
        "dataset=tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "\n",
        "n_steps=100\n",
        "window_length=n_steps+1\n",
        "dataset=dataset.repeat().window(window_length,shift=1,drop_remainder=True)\n",
        "\n",
        "dataset=dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "batch_size=1024\n",
        "dataset=dataset.shuffle(10000).batch(batch_size)\n",
        "dataset=dataset.map(lambda windows: (windows[:,:-1],windows[:,1:]))\n",
        "dataset=dataset.map(lambda X_batch,Y_batch: (tf.one_hot(X_batch,depth=max_id),Y_batch))\n",
        "dataset=dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3lS-BPmqZPS_"
      },
      "outputs": [],
      "source": [
        "model=keras.models.Sequential([\n",
        "    keras.layers.GRU(256, return_sequences=True, input_shape=[None, max_id], dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True, dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,activation='softmax'))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeEMzxhuZTzs",
        "outputId": "00f1a7a3-fc4b-4e5a-90e8-08fc98534f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1594/1594 [==============================] - 382s 236ms/step - loss: 1.9943\n",
            "Epoch 2/10\n",
            "1594/1594 [==============================] - 373s 234ms/step - loss: 1.7113\n",
            "Epoch 3/10\n",
            " 535/1594 [=========>....................] - ETA: 4:06 - loss: 1.7051"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')\n",
        "history=model.fit(dataset,\n",
        "                  steps_per_epoch=train_size/batch_size,\n",
        "                  epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZV9Yy9VSZgWy"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts):\n",
        "    X=np.array(tokenizer.texts_to_sequences(texts))-1\n",
        "    return tf.one_hot(X,max_id)\n",
        "\n",
        "def next_char(text,temperature=1):\n",
        "    X_new=preprocess([text])\n",
        "    y_proba=model.predict(X_new)[0,-1:,:]\n",
        "    rescaled_logits=tf.math.log(y_proba)/temperature\n",
        "    char_id=tf.random.categorical(rescaled_logits,num_samples=1)+1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
        "\n",
        "def complete_text(text,n_chars=50,temperature=0.1):\n",
        "    for _ in range(n_chars):\n",
        "        text+=next_char(text,temperature)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfOmT7lSZooq",
        "outputId": "8047cb34-ec2c-4b39-c1be-bb429a724371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some predicted texts for word 'MNachttischlampe' are as follows:\n",
            " \n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Nachttischlampern, die sechs fürsten rasch zu denkst, oder fin ge\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Nachttischlampenbist werde ich mein elend, wir drohen, die wink i\n",
            "\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Nachttischlampe, davonten weeder um sie wielig für eine gedechtig\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Some predicted texts for word 'Deep Learning' are as follows:\\n \")\n",
        "for i in range(3):\n",
        "  print(complete_text('Deep Learning'))\n",
        "  print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
